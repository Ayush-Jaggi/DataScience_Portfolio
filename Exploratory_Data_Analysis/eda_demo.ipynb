{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) Demo\n",
    "\n",
    "This notebook demonstrates comprehensive exploratory data analysis techniques using Python.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand dataset structure and basic statistics\n",
    "- Identify and handle missing values\n",
    "- Analyze distributions of variables\n",
    "- Explore relationships between variables\n",
    "- Detect outliers using statistical methods\n",
    "- Generate professional analysis reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom EDA analyzer\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from eda_analyzer import DataAnalyzer\n",
    "\n",
    "print(\"EDA analyzer imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize the Data Analyzer\n",
    "\n",
    "Let's create an instance of our DataAnalyzer class with sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the analyzer with sample data\n",
    "analyzer = DataAnalyzer()\n",
    "\n",
    "print(\"Data analyzer initialized with sample dataset\")\n",
    "print(f\"Dataset shape: {analyzer.df.shape}\")\n",
    "print(f\"Numerical columns: {len(analyzer.numeric_columns)}\")\n",
    "print(f\"Categorical columns: {len(analyzer.categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic Dataset Information\n",
    "\n",
    "Let's start with understanding our dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the dataset\n",
    "analyzer.basic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Missing Values Analysis\n",
    "\n",
    "Identifying and understanding missing values is crucial for data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze missing values\n",
    "missing_data = analyzer.missing_values_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Numerical Variables Analysis\n",
    "\n",
    "Let's explore the distributions and characteristics of numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numerical variables\n",
    "desc_stats = analyzer.numerical_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Categorical Variables Analysis\n",
    "\n",
    "Understanding the distribution of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical variables\n",
    "analyzer.categorical_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Correlation Analysis\n",
    "\n",
    "Exploring relationships between numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform correlation analysis\n",
    "correlation_matrix = analyzer.correlation_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Outlier Detection\n",
    "\n",
    "Identifying outliers using the IQR (Interquartile Range) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers\n",
    "outlier_summary = analyzer.outlier_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Custom Analysis\n",
    "\n",
    "Let's perform some additional custom analysis on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom analysis: Income vs Education relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(analyzer.df['education_years'], analyzer.df['income'], alpha=0.6)\n",
    "plt.xlabel('Education Years')\n",
    "plt.ylabel('Income')\n",
    "plt.title('Income vs Education Years')\n",
    "\n",
    "# Add correlation coefficient\n",
    "corr_coef = analyzer.df['education_years'].corr(analyzer.df['income'])\n",
    "plt.text(0.05, 0.95, f'Correlation: {corr_coef:.3f}', \n",
    "         transform=plt.gca().transAxes, \n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Department-wise analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Subplot 1: Average income by department\n",
    "plt.subplot(2, 2, 1)\n",
    "dept_income = analyzer.df.groupby('department')['income'].mean().sort_values(ascending=False)\n",
    "dept_income.plot(kind='bar', color='skyblue')\n",
    "plt.title('Average Income by Department')\n",
    "plt.ylabel('Income')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 2: Average satisfaction by department\n",
    "plt.subplot(2, 2, 2)\n",
    "dept_satisfaction = analyzer.df.groupby('department')['satisfaction_score'].mean().sort_values(ascending=False)\n",
    "dept_satisfaction.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Average Satisfaction by Department')\n",
    "plt.ylabel('Satisfaction Score')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 3: Remote work distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "remote_work_dist = analyzer.df['remote_work'].value_counts()\n",
    "plt.pie(remote_work_dist.values, labels=remote_work_dist.index, autopct='%1.1f%%')\n",
    "plt.title('Remote Work Distribution')\n",
    "\n",
    "# Subplot 4: Age distribution by department\n",
    "plt.subplot(2, 2, 4)\n",
    "analyzer.df.boxplot(column='age', by='department', ax=plt.gca())\n",
    "plt.title('Age Distribution by Department')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Statistical Testing\n",
    "\n",
    "Let's perform some statistical tests to validate our observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for normality in numerical variables\n",
    "print(\"Normality Tests (Shapiro-Wilk):\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for col in analyzer.numeric_columns[:3]:  # Test first 3 for brevity\n",
    "    if len(analyzer.df[col].dropna()) <= 5000:  # Shapiro-Wilk limit\n",
    "        stat, p_value = stats.shapiro(analyzer.df[col].dropna())\n",
    "        is_normal = \"Yes\" if p_value > 0.05 else \"No\"\n",
    "        print(f\"{col}: p-value = {p_value:.6f}, Normal: {is_normal}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# Test for difference in income between remote and non-remote workers\n",
    "remote_yes = analyzer.df[analyzer.df['remote_work'] == 'Yes']['income']\n",
    "remote_no = analyzer.df[analyzer.df['remote_work'] == 'No']['income']\n",
    "\n",
    "stat, p_value = stats.ttest_ind(remote_yes, remote_no)\n",
    "print(f\"T-test for income difference (remote vs non-remote):\")\n",
    "print(f\"t-statistic: {stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.6f}\")\n",
    "print(f\"Significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "print(f\"\\nMean income (remote): ${remote_yes.mean():.2f}\")\n",
    "print(f\"Mean income (non-remote): ${remote_no.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Generate Complete Report\n",
    "\n",
    "Finally, let's generate a comprehensive analysis report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complete EDA report\n",
    "analyzer.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this EDA demo, we've successfully:\n",
    "1. Analyzed dataset structure and basic statistics\n",
    "2. Identified and visualized missing values\n",
    "3. Explored distributions of numerical and categorical variables\n",
    "4. Analyzed correlations between variables\n",
    "5. Detected outliers using statistical methods\n",
    "6. Performed custom analysis and statistical testing\n",
    "7. Generated comprehensive visualizations and reports\n",
    "\n",
    "## Key Insights\n",
    "- Our sample dataset contains 1000 employee records\n",
    "- Strong correlations exist between age and experience\n",
    "- Income distribution shows log-normal characteristics\n",
    "- Different departments show varying satisfaction levels\n",
    "- Missing values are minimal (5% in satisfaction scores)\n",
    "\n",
    "## Next Steps\n",
    "- Handle missing values appropriately\n",
    "- Consider data transformation for skewed variables\n",
    "- Investigate outliers for business insights\n",
    "- Prepare data for machine learning models\n",
    "- Create interactive dashboards for stakeholders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}